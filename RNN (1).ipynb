{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b007a9-3e0e-4df0-9ffe-55192e5f0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87e58ab-e3b3-4f5d-b63d-07c699eba747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generer une serie temporelle sinusoidal\n",
    "def generate_data(timesteps, n_samples):\n",
    "    x= np.linspace(0, 50, timesteps * n_samples)\n",
    "    y= np.sin(x)\n",
    "    return y\n",
    "#parametre\n",
    "timesteps = 50\n",
    "n_samples = 1000\n",
    "#generer les donnees\n",
    "data = generate_data(timesteps, n_samples)\n",
    "#PREPARER LES DONNEES POUR LENTRAINEMENT]\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(data)-timesteps):\n",
    "    x.append(data[i:i + timesteps])\n",
    "    y.append(data[i + timesteps])\n",
    "x= np.array(x)\n",
    "y= np.array(y)\n",
    "#reshape les donnees pour quelle soient compatibles avec entree du rnn\n",
    "x= x.reshape((x.shape[0], x.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c3facd-88a2-4c5d-a43d-ad5af733ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diviser les donneees en train et test\n",
    "split = int(0.8* len(x))\n",
    "x_train, x_test = x[:split], x[split:]\n",
    "y_train, y_test= y[:split],y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe15c32-2ce1-492c-9dc4-8ccf3913d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construire le modele rnn\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', input_shape= (timesteps, 1)))\n",
    "model.add(Dense(1))\n",
    "#compiler le modele\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9077dfb2-77c2-4221-8119-e1f770c74b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0281 - val_loss: 1.1649e-06\n",
      "Epoch 2/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 1.6380e-06 - val_loss: 2.2994e-06\n",
      "Epoch 3/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 1.8798e-06 - val_loss: 1.3183e-06\n",
      "Epoch 4/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 2.0667e-06 - val_loss: 1.4383e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 6.6599e-06 - val_loss: 8.9642e-07\n",
      "Epoch 6/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 3.7671e-06 - val_loss: 1.2208e-06\n",
      "Epoch 7/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 1.9100e-06 - val_loss: 3.2541e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 9.7921e-06 - val_loss: 8.3953e-07\n",
      "Epoch 9/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 3.2045e-06 - val_loss: 9.7475e-07\n",
      "Epoch 10/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 1.3261e-06 - val_loss: 2.2415e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 2.4867e-06 - val_loss: 6.1103e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 3.0195e-06 - val_loss: 3.1830e-07\n",
      "Epoch 13/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 1.5258e-06 - val_loss: 6.2413e-07\n",
      "Epoch 14/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 5.9063e-06 - val_loss: 1.0751e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 1.1657e-05 - val_loss: 1.2138e-07\n",
      "Epoch 16/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 6.3931e-07 - val_loss: 4.6307e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 1.6963e-06 - val_loss: 1.8677e-07\n",
      "Epoch 18/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 2.1234e-06 - val_loss: 3.1674e-07\n",
      "Epoch 19/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 1.1649e-06 - val_loss: 2.5492e-07\n",
      "Epoch 20/20\n",
      "\u001b[1m999/999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 7.3594e-07 - val_loss: 4.9562e-07\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.5698e-07\n",
      "Loss sur l'ensemble de test : 5.045823172622477e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Générer une série temporelle sinusoidale\n",
    "def generate_data(timesteps, n_samples):\n",
    "    x = np.linspace(0, 50, timesteps * n_samples)\n",
    "    y = np.sin(x)\n",
    "    return y\n",
    "\n",
    "# Paramètres\n",
    "timesteps = 50\n",
    "n_samples = 1000\n",
    "\n",
    "# Générer les données\n",
    "data = generate_data(timesteps, n_samples)\n",
    "\n",
    "# Préparer les données pour l'entraînement\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(data) - timesteps):\n",
    "    x.append(data[i:i + timesteps])  # Séquences d'entrée\n",
    "    y.append(data[i + timesteps])   # Valeur cible\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Reshape les données pour qu'elles soient compatibles avec l'entrée du RNN\n",
    "x = x.reshape((x.shape[0], x.shape[1], 1))  # Ajouter la dimension des caractéristiques\n",
    "\n",
    "# Diviser les données en train et test\n",
    "split = int(0.8 * len(x))\n",
    "x_train, x_test = x[:split], x[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Construire le modèle RNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', input_shape=(timesteps, 1)))  # (timesteps, num_features)\n",
    "model.add(Dense(1))  # Prédiction scalaire\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Évaluer le modèle\n",
    "loss = model.evaluate(x_test, y_test)\n",
    "print(f\"Loss sur l'ensemble de test : {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e214643-6abe-4cf9-907f-0e194157ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.5698e-07\n",
      "test loss: 5.045823172622477e-07\n"
     ]
    }
   ],
   "source": [
    "#evaluation du modele:\n",
    "loss = model.evaluate(x_test, y_test)\n",
    "print(f'test loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d686b-ebef-45a9-b6b6-72b9527e43fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
